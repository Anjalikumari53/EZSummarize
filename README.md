# EZSummarize
Automatic Text Summarization

The name of this project is EZSummarize, which is an Automatic Text Summarization Machine learning model that helps users gain insights into the original document without needing to read the entire document.

It aims to investigate the capabilities of LSTM, a recurrent neural network architecture, in generating accurate and meaningful summaries. The objective is to leverage the inherent ability of LSTM to capture long-range dependencies in sequential data, specifically in the context of natural language processing tasks. By employing pre-trained word embeddings and training the LSTM model on diverse datasets, the model seeks to assess its effectiveness in extracting essential information and producing coherent summaries. It also explores the application of the Bart Transformer model, a variant of the Transformer architecture, in the task of automatic text summarization. It utilizes a sequence-to-sequence architecture, where the input text is encoded into a fixed-length vector representation, and then decoded to generate the summary. BART leverages self-attention mechanisms to capture dependencies between words and phrases in the input text, allowing it to produce high-quality summaries.

